{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashtambee/Airline-Passenger-Referral-Prediction/blob/main/Yash_Tambe_Airline_Passenger_Referral_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **✈️Airline Passenger Referral Prediction**    \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1**  - Yash Tambe\n",
        "##### **Team Member 2**  - Chaitanya Chaudhari"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Airline Passenger Referral Prediction capstone project our main objectives to predict whether passengers will refer the airline to their friends. Therefore according to the data given in the dataset, we will implement the Machine learning classification model to predict the right travel airline for the passengers. And accordingly we will make their cross validation and hyper parameter tuning to make the predictions more accurate. For this process, we will try to conditioned our data as per requirement we have."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/yashtambee/Airline-Passenger-Referral-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data includes airline reviews from 2006 to 2019 for popular airlines around the world with multiple choice and free text questions. Data is scraped in Spring 2019.The main objectives to predict whether passengers will refer the airline to their friends."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Begin !**"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Know Your Data**"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "49\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, auc\n",
        "from sklearn.metrics import recall_score,precision_score,classification_report,roc_auc_score,roc_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install eli5\n",
        "import eli5 as eli\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "airline_df = pd.read_excel(\"https://github.com/yashtambee/Airline-Passenger-Referral-Prediction/blob/main/data_airline_reviews.xlsx?raw=true\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.tail()"
      ],
      "metadata": {
        "id": "byfWWP5E_GEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'In the given dataset,\\nThe total number of rows are {airline_df.shape[0]} and \\nThe total number of columns are {airline_df.shape[1]}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "airline_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Understanding Your Variables**"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "airline_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "airline_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**airline**: Name of the airline.\n",
        "\n",
        "**overall**: Overall point is given to the trip between 1 to 10.\n",
        "\n",
        "**author**: Author of the trip\n",
        "\n",
        "**review date**: Date of the Review\n",
        "\n",
        "**customer review**:Review of the customers in free text format\n",
        "\n",
        "**aircraft**: Type of the aircraft\n",
        "\n",
        "**traveller type**: Type of traveler (e.g. business, leisure)\n",
        "\n",
        "**cabin**: Cabin at the flight date flown: Flight date\n",
        "\n",
        "**seat comfort**: Rated between 1-5\n",
        "\n",
        "**cabin service**: Rated between 1-5\n",
        "\n",
        "**foodbev**: Rated between 1-5\n",
        "\n",
        "**entertainment**: Rated between 1-5\n",
        "\n",
        "**ground service**: Rated between 1-5\n",
        "\n",
        "**value for money**: Rated between 1-5\n",
        "\n",
        "**recommended**: Binary, target variable."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Wrangling**"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(airline_df[airline_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# permanently dropping the duplicate rows from the dataset\n",
        "airline_df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "IZIHVXtunqfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the duplicate rows again afer dropping them \n",
        "len(airline_df[airline_df.duplicated()])"
      ],
      "metadata": {
        "id": "QwUcQd0fnsp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the dataset shape after droping the duplicate rows\n",
        "airline_df.shape"
      ],
      "metadata": {
        "id": "gti_UQDqtQQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see after dropping duplicate rows our shape of dataset got reduced from 131895 rows 17 columns to 61184 rows 17 columns"
      ],
      "metadata": {
        "id": "QtPBt3cMn1_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first view of the dataset after dropping the duplicate rows\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "T6RCMNkDu0fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "null_values = airline_df.isna().sum()\n",
        "null_values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.rcParams['figure.figsize'] = (6,5)\n",
        "airline_df.isna().sum().plot(kind = 'bar', color = 'pink')\n",
        "plt.xlabel('Variables with null values')\n",
        "plt.ylabel('Total Null value count',labelpad = 10)\n",
        "plt.title('Null values in dataframe')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Permanently dropping the null values \n",
        "airline_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "TZr3mqTetWSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the dataset shape after droping the null values\n",
        "airline_df.shape"
      ],
      "metadata": {
        "id": "0evgS9BztaaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see after dropping duplicate rows our shape of dataset got reduced from 61184 rows 17 columns to 13189 rows 17 columns"
      ],
      "metadata": {
        "id": "tzEgm0Hyocus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable \n",
        "# creating an object named required_variables that will contain all \n",
        "required_variables = airline_df.loc[:,:]\n",
        "for i in required_variables.columns :\n",
        "  print(f'Unique values for variable {i} is as below :')\n",
        "  print(required_variables[i].unique())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA (Explorative Data Analysis)**"
      ],
      "metadata": {
        "id": "V4TCrfUl3w5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysing which airline has most no of overall ratings points\n"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# performing groupby operation to find the best airline with best overall perfromance\n",
        "most_overall_rating = airline_df.groupby('airline')['overall'].sum().sort_values(ascending= False)\n",
        "most_overall_rating"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the above result \n",
        "plt.rcParams['figure.figsize'] = (25,8)\n",
        "most_overall_rating.plot(kind = 'bar')\n",
        "\n",
        "# assigning title, x label , y label to the plot\n",
        "plt.xlabel('airline', labelpad = 17, fontsize = 12)\n",
        "plt.ylabel('overall ratings points', labelpad = 17, fontsize = 12)\n",
        "plt.title('', pad = 19, fontsize = 14)\n"
      ],
      "metadata": {
        "id": "DdvDaxJTBY7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above bar plot we can see that China Southern Airlines has the most numbers of the overall reviews"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysing which airline is the most worthy for money"
      ],
      "metadata": {
        "id": "sX82mBmKDhYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the most worthy for money airline using groupby operation on 'airline' & 'value for money' feature \n",
        "airline_most_worthy_for_money = airline_df.groupby('airline')['value_for_money'].sum().sort_values(ascending=False)\n",
        "airline_most_worthy_for_money"
      ],
      "metadata": {
        "id": "JLA2SBsbDn8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the above result \n",
        "plt.rcParams['figure.figsize'] = (25,8)\n",
        "airline_most_worthy_for_money.plot(kind = 'bar')\n",
        "\n",
        "# assigning title, x label , y label to the plot\n",
        "plt.xlabel('airline', labelpad = 17, fontsize = 12)\n",
        "plt.ylabel('value for money ratings points', labelpad = 17, fontsize = 12)\n",
        "plt.title('', pad = 19, fontsize = 14)"
      ],
      "metadata": {
        "id": "dfnRx5WpGUyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above pie plot we can see that the 'China Southern Airlines' is the most worthy for money airline and the 'airBaltic' airline is the least worthy for money travel"
      ],
      "metadata": {
        "id": "78fa5hcEFPH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysing the food beverages and entertaiment average ratings given by passenger\n"
      ],
      "metadata": {
        "id": "Q7zuDi5HG8Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the average ratings of food beverages and entertaiment\n",
        "avg_rating_foodbev_and_entertainment = airline_df.groupby('cabin')[['food_bev','entertainment']].mean()\n",
        "avg_rating_foodbev_and_entertainment"
      ],
      "metadata": {
        "id": "I_KwtcfMN9jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the average food beverages & entertainment ratings given by the passengers\n",
        "plt.rcParams['figure.figsize'] = (7,5)\n",
        "avg_rating_foodbev_and_entertainment.plot(kind = 'bar')\n",
        "plt.ylim([0,4])\n",
        "plt.xticks(rotation = 50)\n",
        "plt.ylabel('avg  food beverages and entertainment ratings',fontsize = 9,labelpad = 10)\n",
        "plt.xlabel('cabin type',fontsize = 9)"
      ],
      "metadata": {
        "id": "2YQ-8mbRNMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Economy class has the lowest average food beverages and entertaining ratings as compared to other classes\n",
        "\n",
        "Whereas the Business Class has the highest food beverages and entertaining ratings"
      ],
      "metadata": {
        "id": "75WECqDQW42N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysing top 10 airline with most number of trips ?"
      ],
      "metadata": {
        "id": "35fNb_Dl-Hpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the top 10 airlines with most no. of trips\n",
        "top_10_airlines = airline_df['airline'].value_counts().head(10)"
      ],
      "metadata": {
        "id": "RX_MpXeM-bs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the top 10 airlines with most no. of trips\n",
        "plt.rcParams['figure.figsize'] = (10,8)\n",
        "top_10_airlines.plot(kind = 'bar')\n",
        "plt.xticks(rotation = 50)\n",
        "plt.ylabel('No. of trips',fontsize = 12,labelpad = 14)\n",
        "plt.xlabel('airlines',fontsize = 12,labelpad = 14)\n",
        "plt.title('top 10 airlines with most no. of trips',pad = 14,fontsize = 12)"
      ],
      "metadata": {
        "id": "ei6DWo4j_KHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "British Airways ranked at the top among the list of top 10 airlines with most number of trips"
      ],
      "metadata": {
        "id": "Mg_E6FGiqoNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the distribution of dependent variable "
      ],
      "metadata": {
        "id": "1kwMm-cJD_ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of values of YES - NO  \n",
        "target_distribution = airline_df['recommended'].value_counts()\n",
        "target_distribution"
      ],
      "metadata": {
        "id": "yNJyDcQj33rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the distribution of the dependent variable\n",
        "plt.rcParams['figure.figsize'] = (5,5)\n",
        "sns.countplot(x = airline_df['recommended'])\n",
        "plt.title('Distribution of Dependent Variable : recommended ',pad = 12)\n",
        "plt.xlabel('recommended',fontsize = 8.5)\n",
        "plt.ylabel('count',fontsize = 8.5)"
      ],
      "metadata": {
        "id": "uBcKwQpG33n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above visualization, we got know that among nearly 13000 times passengers have travelled by flights, they recommended 8802 times that we can travel by airway."
      ],
      "metadata": {
        "id": "D1vAYr_JP3-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the percentage of distribution of yes v/s no\n",
        "target_distribution.plot(kind = 'pie',autopct='%.1f%%', shadow = True, explode = [0.2,0.1], fontsize = 12)"
      ],
      "metadata": {
        "id": "kb8EZaGvNr-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Distribution of the Independent variables\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "faLhF-UzBmMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histogram to see the distribution of the data\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "ax = fig.gca()\n",
        "airline_df.hist(ax = ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JtKS9msLHKe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the relationship between categorical dependent variable and independent variable"
      ],
      "metadata": {
        "id": "sNkvekUEHM4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the categorical variable list \n",
        "categorical_features = ['overall','seat_comfort','cabin_service','food_bev','entertainment','ground_service','value_for_money']"
      ],
      "metadata": {
        "id": "-dxiltlgEIBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the relationship between categorical dependent & independent variables\n",
        "for col in categorical_features : \n",
        "  plt.figure(figsize=(8,5))\n",
        "  sns.violinplot(x=col, y=\"recommended\", data=airline_df, hue = 'recommended') # plots the violin plot\n",
        "  plt.title(\"Relationship between recommended &\" + \" \" + col)                  # assining title to the plot"
      ],
      "metadata": {
        "id": "xetRsCrPFCDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Multi - Collinearity "
      ],
      "metadata": {
        "id": "aD_UsYzfA9Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the dependent variable \"recommended\" as it is going to be used for checking multicollinearity\n",
        "airline_df['recommended'] = airline_df['recommended'].map({'yes':1,'no':0})"
      ],
      "metadata": {
        "id": "Z895THqdOzby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the correlations among the features\n",
        "airline_df.corr()"
      ],
      "metadata": {
        "id": "Eg1OjRmFAqN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyisng the Correlations of features using the heatmap\n",
        "plt.rcParams['figure.figsize'] = (8,6)\n",
        "sns.heatmap(abs(airline_df.corr()),annot = True, cmap = 'Blues')"
      ],
      "metadata": {
        "id": "WLQeC_MFZ_VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIF (Variance Inflation Factor) Analysis of Independent Variables\n",
        "Variance inflation factor (VIF) is a measure of the amount of multicollinearity in a set of multiple regression variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "1fapIYJKPDyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to calculate the VIF \n",
        "def cal_vif(x) :\n",
        "# calculating vif\n",
        "  vif = pd.DataFrame()\n",
        "  vif['variables'] = x.columns # rows will be column of the passed dataset\n",
        "  vif['VIF'] = [variance_inflation_factor(x.values,i) for i in range(x.shape[1])] # df.shape[1] means shape of the columns\n",
        "                                                                                  \n",
        "  return(vif) # returning vif df"
      ],
      "metadata": {
        "id": "f1fNzAavPIqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_vif(airline_df[[i for i in airline_df.describe().columns if i not in ['airline','author','review_date','customer_review','aircraft',\n",
        "                                                                          'traveller_type','cabin','date_flown','route','recommended']]])"
      ],
      "metadata": {
        "id": "6Z7meCX9PLi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the 'overall' and 'value for money' feature has very VIF factor & has very high collinearity of 0.87\n",
        "\n",
        "Also 'overall' and 'recommended' has correlation of 0.86\n",
        "\n",
        "'value for money' and 'recommended' has correlation of  0.79\n",
        "\n",
        "So we will drop 'value_for_money' feature\n",
        "\n",
        "Further we are having high VIF values for remaining features but they are not exhibiting very high correlation in the heatmap plot. \n",
        "\n",
        "So we will conclude our VIF process here"
      ],
      "metadata": {
        "id": "4KF8t0JiPtya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping 'value_for_money' feature from the VIF list\n",
        "cal_vif(airline_df[[i for i in airline_df.describe().columns if i not in ['airline','author','review_date','customer_review',\n",
        "                                                                          'aircraft','traveller_type','cabin','date_flown','route',\n",
        "                                                                          'recommended','value_for_money']]])"
      ],
      "metadata": {
        "id": "-Q5bZ5wzQmqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyisng the Correlations of features using the heatmap after dropping the 'overall' feature\n",
        "plt.rcParams['figure.figsize'] = (8,6)\n",
        "sns.heatmap(airline_df[['overall','seat_comfort','cabin_service','food_bev','entertainment','ground_service','recommended']].corr(),annot = True, cmap = 'Blues')"
      ],
      "metadata": {
        "id": "gciKcCTnQtEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Detection"
      ],
      "metadata": {
        "id": "AjtB5ucTSesl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking outliers for the box plot\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.set(rc={'figure.figsize':(13.7,8.27)})\n",
        "ax = sns.boxplot(data=airline_df, orient=\"v\", palette=\"Set2\")"
      ],
      "metadata": {
        "id": "hekc9X1TJUfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With these our Explorative Data Analysis is complete"
      ],
      "metadata": {
        "id": "_UVB7qjBKBhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Engineering & Data Pre-processing**"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducing cardinality & Feature Encoding"
      ],
      "metadata": {
        "id": "zQIoDrjIyUcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the original dataset & dropping 'value_for_money' feature from it as per our VIF analysis\n",
        "airline_df_cp = airline_df.copy().drop('value_for_money',axis = 1)"
      ],
      "metadata": {
        "id": "FOf900fFQV2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first view of the copied dataset after droping the 'value_for_money' feature\n",
        "airline_df_cp.head()"
      ],
      "metadata": {
        "id": "BSYtARKTQvYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of columns whose cardinality is to be checked\n",
        "cols_for_cardinality_check = ['airline','overall','seat_comfort','cabin_service','food_bev','entertainment','cabin','traveller_type','ground_service','recommended']"
      ],
      "metadata": {
        "id": "EwUUz8KEyqDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of labels = cardinality\n",
        "#Let's now check if our categorical variables have a huge number of categories. \n",
        "#This may be a problem for some machine learning models.\n",
        "for var in airline_df_cp[cols_for_cardinality_check]:\n",
        "    print(var, ' contains ', len(airline_df_cp[var].unique()), ' labels')"
      ],
      "metadata": {
        "id": "sWFH7TB6yU4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the original data\n",
        "airline_df_cp['cabin'] = airline_df_cp['cabin'].map({'Economy Class':0 ,'Business Class':1 ,'First Class':2 ,'Premium Economy':3})\n",
        "airline_df_cp['traveller_type'] = airline_df_cp['traveller_type'].map({'Solo Leisure':0 ,'Couple Leisure':1 ,'Business':2 ,'Family Leisure':3})\n",
        "\n",
        "# creating dummies values for the airline feature\n",
        "airline_df_cp = pd.get_dummies(airline_df_cp, columns=['airline'])"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first view of data after encoding\n",
        "airline_df_cp.head()"
      ],
      "metadata": {
        "id": "zkj9IFk32Ofc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape of data after feature encoding\n",
        "airline_df_cp.shape"
      ],
      "metadata": {
        "id": "SqQ1oFnx3SoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking all columns in new data set after feature encoding & creating dummy variable  \n",
        "airline_df_cp.columns"
      ],
      "metadata": {
        "id": "fqFShk9u50yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Class Imbalance of Target variable "
      ],
      "metadata": {
        "id": "vEJDi2xiSNB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the total number of each class present in the dataset\n",
        "# here yes = 1, no = 0\n",
        "airline_df_cp['recommended'].value_counts()"
      ],
      "metadata": {
        "id": "Y25n39frOScf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the total number of rows in the dataset\n",
        "total = airline_df_cp['recommended'].value_counts()[1] + airline_df_cp['recommended'].value_counts()[0]\n",
        "print('total target variable label count :',total)\n",
        "\n",
        "# calculating the percentage of observations of dependent variable belonging to the class 1\n",
        "percentage_class_1 = round((airline_df_cp['recommended'].value_counts()[1]/total)*100,2)\n",
        "print('Percentage of class 1 :',percentage_class_1)\n",
        "\n",
        "# calculating the percentage of observations of dependent variable belonging to the class 0\n",
        "percentage_class_0 = round((airline_df_cp['recommended'].value_counts()[0]/total)*100,2)\n",
        "print('Percentage of class 0 :',percentage_class_0)"
      ],
      "metadata": {
        "id": "JhUlpRDvOSaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are having the class imbalance as the class 1 is almost double(2x) of class 0 \n",
        "\n",
        "The model will accurately predict the class 1 but might create error in prediction of class 0 as during training the model it will get trained more on the class 1 basis\n",
        "\n",
        "So we have to perform class imbalance handling operation to fix this problem & we will use Synthetic Minority Oversampling Technique (SMOTE) process"
      ],
      "metadata": {
        "id": "3jYBwOsZXpCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Minority Oversampling Technique (SMOTE)\n"
      ],
      "metadata": {
        "id": "KZgi7oLIXmpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining x_data to pass in smote analysis \n",
        "x_data = airline_df_cp.drop(columns = ['date_flown','route','aircraft','customer_review','review_date','author','recommended'],axis =1) \n",
        "\n",
        "# defining object of the class SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(x_data, airline_df_cp['recommended'])\n",
        "\n",
        "print('Original dataset shape', len(airline_df_cp))\n",
        "print('Resampled dataset shape', len(y_smote))"
      ],
      "metadata": {
        "id": "7oj4_YjHUWJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the total number of each class present in the dataset after performing the SMOTE\n",
        "# here yes = 1, no = 0\n",
        "y_smote.value_counts()"
      ],
      "metadata": {
        "id": "9bjWXycoUWF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see after performing the SMOTE method both the class of the feature 'recommended' are balance with 8802 values belonging to class 1 & 8802 values belonging to class 0"
      ],
      "metadata": {
        "id": "Cz2AXwA2ZtTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Test Split**"
      ],
      "metadata": {
        "id": "KLYXshRObe6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset into 80(training) - 20(testing) ratio\n",
        "X_train,X_test,y_train,y_test = train_test_split(x_smote,y_smote,test_size = 0.2, random_state=0) "
      ],
      "metadata": {
        "id": "74IHBIvoUWDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the shape of the test & train dataset\n",
        "print('The shape of X_train is',X_train.shape)\n",
        "print('The shape of X_test is',X_test.shape)\n",
        "print('The shape of y_train is',y_train.shape)\n",
        "print('The shape of y_test is',y_test.shape)   "
      ],
      "metadata": {
        "id": "yX2upyx0UWAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ML Model Implementation**"
      ],
      "metadata": {
        "id": "OlJuQ1tQdltP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Models used for the Classsification of airline recommendation as 'yes' or 'no' are :\n",
        "\n",
        "1. Logistic Regression \n",
        "2. Decision Tree Classifier\n",
        "3. K-Nearest Neighbors \n",
        "4. Support Vector Machine  \n",
        "5. XG Boost Classifier"
      ],
      "metadata": {
        "id": "d3ercZnxeA2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression "
      ],
      "metadata": {
        "id": "X8bUn863d2r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dict of parameters to find the most optimum parameters using gridsearchCV for LogisticRegression\n",
        "params = {'penalty':['l1','l2'],\n",
        "         'C' : [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100,1e-3,1e+4,1e+5,1e+6],\n",
        "         'class_weight':['balanced',None]}\n",
        "         \n",
        "# implementing gridsearchcv\n",
        "logistic_clf = GridSearchCV(LogisticRegression(),param_grid=params,cv=10, scoring='roc_auc')"
      ],
      "metadata": {
        "id": "v7M4cQSIp0Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the LogisticRegression model\n",
        "logistic_clf.fit(X_train,y_train)\n",
        "\n",
        "# the best optimum parameters resulted from gridsearchcv\n",
        "logistic_clf.best_params_"
      ],
      "metadata": {
        "id": "2Vmw7qUTp0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions on test dataset \n",
        "logistic_predict = logistic_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "sY7Egc2ap0To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the LogisticRegression model on test dataset\n",
        "logistic_accuracy = accuracy_score(y_test,logistic_predict)\n",
        "print(f\"Using logistic regression we get an accuracy of {round(logistic_accuracy*100,2)}%\")"
      ],
      "metadata": {
        "id": "XK0EixpTp0RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test & train dataset roc-auc score\n",
        "print('Train ROC-AUC score : ', logistic_clf.best_estimator_.score(X_train,y_train))\n",
        "print('Test ROC-AUC score : ', logistic_clf.best_estimator_.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "6XoCdCRgp0Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix for LogisticRegression Model\n",
        "cm=confusion_matrix(y_test,logistic_predict)\n",
        "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (5,4))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\")"
      ],
      "metadata": {
        "id": "lupGj5Rgp0LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report for the LogisticRegression model\n",
        "print(classification_report(y_test,logistic_predict))"
      ],
      "metadata": {
        "id": "Ny6Kwo2Zp0IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC\n",
        "probs_lgr = logistic_clf.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs_lgr = probs_lgr[:, 1]\n",
        "# calculate AUC\n",
        "log_auc = roc_auc_score(y_test, probs_lgr)\n",
        "\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs_lgr)\n",
        "# plot curve\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(5,4)) \n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.title(f\"AUC = {round(log_auc,3)}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-17skEs_q4V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier"
      ],
      "metadata": {
        "id": "K7VH2JBmqMlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dict of parameter for gridsearchcv\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5,10],\n",
        "    'min_samples_split': [2, 3, 4,7,10,50,100],\n",
        "    'min_samples_leaf': [1, 2, 3,4,5],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "# implementing the gridsearchcv to find the best optimal parameters for our model \n",
        "decision_tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid, cv=10, n_jobs=-1)\n",
        "\n",
        "# fitting the DecisionTreeClassifier model\n",
        "decision_tree_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1pesnEMSdElC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewving the best resulted parameter from the gridsearchcv\n",
        "decision_tree_clf.best_estimator_"
      ],
      "metadata": {
        "id": "3jlUivyMdEh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions on test dataset\n",
        "decision_tree_predict = decision_tree_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "89rfmUAldEew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the DecisionTreeClassifier model \n",
        "decision_tree_accuracy = accuracy_score(y_test,decision_tree_predict)\n",
        "print(f\"Using decision_tree_classifier we get an accuracy of {round(decision_tree_accuracy*100,2)}%\")"
      ],
      "metadata": {
        "id": "cVGKDjRY8UUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test & train dataset roc-auc score \n",
        "print('Train ROC-AUC score : ', decision_tree_clf.best_estimator_.score(X_train,y_train))\n",
        "print('Test ROC-AUC score : ', decision_tree_clf.best_estimator_.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "C-nes6Lj8UQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix of Decision_tree_classifier Model\n",
        "tree_cm =confusion_matrix(y_test,decision_tree_predict)\n",
        "conf_matrix=pd.DataFrame(data=tree_cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (5,4))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\")"
      ],
      "metadata": {
        "id": "CLaruOvJ8wfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report for the DecisionTreeClassifier model\n",
        "print(classification_report(y_test,decision_tree_predict))"
      ],
      "metadata": {
        "id": "lKbEUENX8wck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC\n",
        "probs_dct = decision_tree_clf.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs_dct = probs_dct[:, 1]\n",
        "# calculate AUC\n",
        "dct_auc = roc_auc_score(y_test, probs_dct)\n",
        "\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs_dct)\n",
        "# plot curve\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.title(f\"AUC = {round(dct_auc,3)}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yd3CsgI28wat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K Nearest Neighbors "
      ],
      "metadata": {
        "id": "xEahQplLj4FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dict of parameters for KNeighborsClassifier\n",
        "param_grid_knn = {'n_neighbors':np.arange(1,50)}\n",
        "\n",
        "# implementing the gridsearchcv to find the best optimal parameters for our model \n",
        "knn_clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid_knn, cv=10)\n",
        "\n",
        "# training the KNN model\n",
        "knn_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "d-i45uhKj4iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewving the best resulted parameter from the gridsearchcv\n",
        "knn_clf.best_estimator_"
      ],
      "metadata": {
        "id": "Z6nhOd-wj4wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions on test dataset\n",
        "knn_clf_predict = knn_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "yEzqUAZ5j4st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the KNN model\n",
        "knn_accuracy = accuracy_score(y_test,knn_clf_predict)\n",
        "print(f\"Using knn_classifier we get an accuracy of {round(knn_accuracy*100,2)}%\")"
      ],
      "metadata": {
        "id": "sfP-ckR_j4qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test & train dataset roc-auc score\n",
        "print('Train ROC-AUC score : ', knn_clf.best_estimator_.score(X_train,y_train))\n",
        "print('Test ROC-AUC score : ', knn_clf.best_estimator_.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "Qzj4HryCj4n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix of knn_classifier Model\n",
        "knn_cm =confusion_matrix(y_test,knn_clf_predict)\n",
        "conf_matrix=pd.DataFrame(data=knn_cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (5,4))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\")"
      ],
      "metadata": {
        "id": "d1dr2foZj30x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report for the DecisionTreeClassifier model\n",
        "print(classification_report(y_test,knn_clf_predict))"
      ],
      "metadata": {
        "id": "pxJ9oeMrqVMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC\n",
        "probs_knn = knn_clf.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs_knn = probs_knn[:, 1]\n",
        "# calculate AUC\n",
        "knn_auc = roc_auc_score(y_test, probs_knn)\n",
        "\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs_knn)\n",
        "# plot curve\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.title(f\"AUC = {round(knn_auc,3)}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pQIczyMjqSCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost classifier"
      ],
      "metadata": {
        "id": "9IBZakz4cstY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating object xgb_clf of class XGBoost Classifier model\n",
        "xgb_clf = XGBClassifier()\n",
        "# training the XGBoost classifier\n",
        "xgb_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "WZul2ZxNdmY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions on test dataset\n",
        "xgb_predict = xgb_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "G7tDtNzufGLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the accuracy of the XGBoost classifier model\n",
        "xgb_accuracy = accuracy_score(y_test,xgb_predict)\n",
        "print(f\"Using XG boost we get an accuracy of {round(xgb_accuracy*100,2)}%\")"
      ],
      "metadata": {
        "id": "TIbZv5b6fD4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix of XG boost Classifier\n",
        "cm_xgb =confusion_matrix(y_test,xgb_predict)\n",
        "conf_matrix=pd.DataFrame(data=cm_xgb,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (5,4))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\")"
      ],
      "metadata": {
        "id": "7W2vW_ZefCie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the classification report of the XGBoost classifier\n",
        "print(classification_report(y_test, xgb_predict))"
      ],
      "metadata": {
        "id": "vOCSHhkafBAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC \n",
        "probs_xgb = xgb_clf.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs_xgb = probs_xgb[:, 1]\n",
        "# calculate AUC\n",
        "xgb_auc = roc_auc_score(y_test, probs_xgb)\n",
        "\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs_xgb)\n",
        "# plot curve\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.title(f\"AUC = {round(xgb_auc,3)}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1O5OscOcqR61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "z5e2N1sg_lNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating object svm_clf of SVC class\n",
        "svm_clf=SVC(kernel='linear', probability=True)"
      ],
      "metadata": {
        "id": "dCBZ7UcY8wW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the classifier\n",
        "svm_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "HHEdvCRf8UIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions on test dataset \n",
        "svm_predict = svm_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "pMX4cV1iCCyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting accuracy of the SVM model on the test dataset\n",
        "svm_accuracy = accuracy_score(y_test,svm_predict)\n",
        "print(f\"Using Support Vector Machine we get an accuracy of {round(svm_accuracy*100,2)}%\")"
      ],
      "metadata": {
        "id": "wgKU_tPYCCuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix of SVM \n",
        "svm_cm=confusion_matrix(y_test,svm_predict)\n",
        "conf_matrix=pd.DataFrame(data=svm_cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (5,4))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\")"
      ],
      "metadata": {
        "id": "yyjJ3HBrCCr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting classification report of the SVM \n",
        "print(classification_report(y_test, svm_predict))"
      ],
      "metadata": {
        "id": "2HVJBVwRCCpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC \n",
        "probs_svm = svm_clf.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs_svm = probs_svm[:, 1]\n",
        "# calculate AUC\n",
        "svc_auc = roc_auc_score(y_test, probs_svm)\n",
        "\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs_svm)\n",
        "# plot curve\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.title(f\"AUC = {round(svc_auc,3)}\")\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "KHTpCQ5HCCmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Performances"
      ],
      "metadata": {
        "id": "nShh8HVPtb0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe to store the evaluation metrics of the applied ML models in one table\n",
        "final_performance_report = pd.DataFrame({\n",
        "    \"Logistic regression\":{'Test Accuracy':logistic_accuracy.round(3),'Precision': precision_score(y_test, logistic_predict).round(3),'Recall': recall_score(y_test, logistic_predict).round(3),'F1 Score': f1_score(y_test, logistic_predict).round(3), 'AUC':log_auc.round(3)},\n",
        "    \"Decision Tree\":{'Test Accuracy':decision_tree_accuracy.round(3),'Precision': precision_score(y_test, decision_tree_predict).round(3),'Recall': recall_score(y_test, decision_tree_predict).round(3),'F1 Score': f1_score(y_test, decision_tree_predict).round(3), 'AUC':dct_auc.round(3)},\n",
        "    \"K Nearest Neighbours\":{'Test Accuracy':knn_accuracy.round(3),'Precision': precision_score(y_test, knn_clf_predict).round(3),'Recall': recall_score(y_test, knn_clf_predict).round(3),'F1 Score': f1_score(y_test, knn_clf_predict).round(3), 'AUC':knn_auc.round(3)},\n",
        "    \"XG Boost\":{'Test Accuracy':xgb_accuracy.round(3),'Precision': precision_score(y_test, xgb_predict).round(3),'Recall': recall_score(y_test, xgb_predict).round(3),'F1 Score': f1_score(y_test, xgb_predict).round(3), 'AUC':xgb_auc.round(3)},\n",
        "    \"Support vector machine\":{'Test Accuracy':svm_accuracy.round(3),'Precision': precision_score(y_test, svm_predict).round(3),'Recall': recall_score(y_test, svm_predict).round(3),'F1 Score': f1_score(y_test, svm_predict).round(3), 'AUC':svc_auc.round(3)}\n",
        "}).T"
      ],
      "metadata": {
        "id": "0B0Q0QoHCCjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_performance_report"
      ],
      "metadata": {
        "id": "oo1yeGMmwxIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above performance table we can say that ,\n",
        "\n",
        "**XGBoost** & **Support Vector Machine** are the Best Performing Models offering F1 score of 95% as compared to other implemented ML models"
      ],
      "metadata": {
        "id": "Ysl6Pz-n4hP7"
      }
    }
  ]
}